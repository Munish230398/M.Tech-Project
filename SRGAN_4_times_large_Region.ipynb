{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jWAn34dWv2Nz"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "# xarray for working with labeled multi-dimensional arrays and datasets\n",
        "import xarray as xr\n",
        "\n",
        "# numpy for numerical computations\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "\n",
        "# train_test_split for splitting the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# tqdm for creating progress bars\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "# Importing Keras libraries and modules for building the neural network\n",
        "from keras import layers, Model\n",
        "from keras.layers import Input, Conv2D, PReLU, BatchNormalization, Flatten\n",
        "from keras.layers import UpSampling2D, LeakyReLU, Dense, add, Cropping2D\n",
        "from keras.models import load_model  # For loading pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdL2RpkHws_w"
      },
      "outputs": [],
      "source": [
        "# Open the dataset using xarray\n",
        "# This dataset is in NetCDF format and contains the data for training the SRGAN model\n",
        "data = xr.open_dataset('adaptor.mars.internal-1699024719.206968-18137-18-9d14156f-5adf-4abf-880e-6eb4422da3d2.nc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0lisDF6w2t9"
      },
      "outputs": [],
      "source": [
        "# Extracting the 'msl' (mean sea level pressure) data from the dataset\n",
        "# taking every 10th value along the first dimension\n",
        "press = data['msl'][::10,1::,::]\n",
        "\n",
        "# Assign the data to hr_data (high-resolution data)\n",
        "hr_data = press\n",
        "\n",
        "# Normalize the high-resolution data\n",
        "# The normalization is done by subtracting the minimum value and dividing by the range (max - min)\n",
        "hr_data = (hr_data - hr_data.min(dim=('latitude', 'longitude'))) / (hr_data.max(dim=('latitude', 'longitude')) - hr_data.min(dim=('latitude', 'longitude')))\n",
        "\n",
        "# Convert the xarray DataArray to a NumPy array\n",
        "high_res = np.array(hr_data)\n",
        "\n",
        "# Repeat the high-resolution data along a new axis to match the required input shape for the model\n",
        "# Adding a new axis to match the expected input shape for the model\n",
        "high_res_data = np.repeat(high_res[:,:,:,np.newaxis], 1, axis=3)\n",
        "\n",
        "# Check the shape of the high-resolution data\n",
        "high_res_data.shape\n",
        "\n",
        "# Downsample the data to create low-resolution data by taking every 4th value along the second and third dimensions\n",
        "lr_data = press[:,::4,::4]\n",
        "\n",
        "# Normalize the low-resolution data\n",
        "# The normalization is done by subtracting the minimum value and dividing by the range (max - min)\n",
        "lr_data = (lr_data - lr_data.min(dim=('latitude', 'longitude'))) / (lr_data.max(dim=('latitude', 'longitude')) - lr_data.min(dim=('latitude', 'longitude')))\n",
        "\n",
        "# Convert the xarray DataArray to a NumPy array\n",
        "low_res = np.array(lr_data)\n",
        "\n",
        "# Repeat the low-resolution data along a new axis to match the required input shape for the model\n",
        "# Adding a new axis to match the expected input shape for the model\n",
        "low_res_data = np.repeat(low_res[:,:,:,np.newaxis], 1, axis=3)\n",
        "\n",
        "# Check the shape of the low-resolution data\n",
        "low_res_data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and test sets\n",
        "# Using 80% of the data for training and 20% for testing\n",
        "lr_train_full, lr_test, hr_train_full, hr_test = train_test_split(low_res_data, high_res_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further splitting the training data into training and validation sets\n",
        "# Using 80% of the training data for actual training and 20% for validation\n",
        "lr_train, lr_val, hr_train, hr_val = train_test_split(lr_train_full, hr_train_full, test_size=0.2, random_state=42)\n",
        "\n",
        "# Defining the shapes of the high-resolution and low-resolution training data\n",
        "hr_shape = (hr_train.shape[1], hr_train.shape[2], hr_train.shape[3])\n",
        "lr_shape = (lr_train.shape[1], lr_train.shape[2], lr_train.shape[3])\n",
        "\n",
        "# Creating input layers for the low-resolution and high-resolution data\n",
        "lr_ip = Input(shape=lr_shape)\n",
        "hr_ip = Input(shape=hr_shape)\n",
        "\n",
        "# Print the shapes of the input layers to verify\n",
        "print(hr_ip.shape, lr_ip.shape)\n"
      ],
      "metadata": {
        "id": "5lN4XDUIym_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxZwxJf7ubCm"
      },
      "outputs": [],
      "source": [
        "# Define a residual block for the generator model\n",
        "def res_block(ip):\n",
        "    # First convolutional layer with batch normalization and PReLU activation\n",
        "    res_model = Conv2D(64, (3, 3), padding='same')(ip)\n",
        "    res_model = BatchNormalization(momentum=0.5)(res_model)\n",
        "    res_model = PReLU(shared_axes=[1, 2])(res_model)\n",
        "\n",
        "    # Second convolutional layer with batch normalization\n",
        "    res_model = Conv2D(64, (3, 3), padding='same')(res_model)\n",
        "    res_model = BatchNormalization(momentum=0.5)(res_model)\n",
        "\n",
        "    # Add the input to the output to create a residual connection\n",
        "    return add([ip, res_model])\n",
        "\n",
        "# Define an upscale block for the generator model\n",
        "def upscale_block(ip):\n",
        "    # Convolutional layer followed by upsampling and PReLU activation\n",
        "    up_model = Conv2D(256, (3, 3), padding='same')(ip)\n",
        "    up_model = UpSampling2D(size=2)(up_model)\n",
        "    up_model = PReLU(shared_axes=[1, 2])(up_model)\n",
        "\n",
        "    return up_model\n",
        "\n",
        "# Define the generator model\n",
        "def create_gen(gen_ip, num_res_block):\n",
        "    # Initial convolutional layer with PReLU activation\n",
        "    layers = Conv2D(64, (9, 9), padding='same')(gen_ip)\n",
        "    layers = PReLU(shared_axes=[1, 2])(layers)\n",
        "\n",
        "    # Store the output of the first layer for later\n",
        "    temp = layers\n",
        "\n",
        "    # Add a specified number of residual blocks\n",
        "    for i in range(num_res_block):\n",
        "        layers = res_block(layers)\n",
        "\n",
        "    # Convolutional layer with batch normalization\n",
        "    layers = Conv2D(64, (3, 3), padding='same')(layers)\n",
        "    layers = BatchNormalization(momentum=0.5)(layers)\n",
        "\n",
        "    # Add the initial layer output to the current output to create a residual connection\n",
        "    layers = add([layers, temp])\n",
        "\n",
        "    # Add two upscale blocks\n",
        "    layers = upscale_block(layers)\n",
        "    layers = upscale_block(layers)\n",
        "\n",
        "    # Final convolutional layer to produce the output image\n",
        "    op = Conv2D(1, (9, 9), padding='same')(layers)\n",
        "\n",
        "    return Model(inputs=gen_ip, outputs=op)\n",
        "\n",
        "# Define a discriminator block\n",
        "def discriminator_block(ip, filters, strides=1, bn=True):\n",
        "    # Convolutional layer followed by LeakyReLU activation\n",
        "    disc_model = Conv2D(filters, (3, 3), strides=strides, padding='same')(ip)\n",
        "    disc_model = LeakyReLU(alpha=0.2)(disc_model)\n",
        "\n",
        "    # Optionally add batch normalization\n",
        "    if bn:\n",
        "        disc_model = BatchNormalization(momentum=0.8)(disc_model)\n",
        "\n",
        "    return disc_model\n",
        "\n",
        "# Define the discriminator model\n",
        "def create_disc(disc_ip):\n",
        "    df = 64  # Number of filters\n",
        "\n",
        "    # Add a series of discriminator blocks with increasing filters and strides\n",
        "    d1 = discriminator_block(disc_ip, df, bn=False)\n",
        "    d2 = discriminator_block(d1, df, strides=2)\n",
        "    d3 = discriminator_block(d2, df * 2)\n",
        "    d4 = discriminator_block(d3, df * 2, strides=2)\n",
        "    d5 = discriminator_block(d4, df * 4)\n",
        "    d6 = discriminator_block(d5, df * 4, strides=2)\n",
        "    d7 = discriminator_block(d6, df * 8)\n",
        "    d8 = discriminator_block(d7, df * 8, strides=2)\n",
        "\n",
        "    # Flatten the output and add dense layers\n",
        "    d8_5 = Flatten()(d8)\n",
        "    d9 = Dense(df * 16)(d8_5)\n",
        "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "\n",
        "    # Final dense layer with sigmoid activation to produce a validity score\n",
        "    validity = Dense(1, activation='sigmoid')(d10)\n",
        "\n",
        "    return Model(disc_ip, validity)\n",
        "\n",
        "# Define a VGG model for feature extraction\n",
        "def build_vgg(hr_shape):\n",
        "    from keras.applications import VGG19\n",
        "    # Load the VGG19 model pre-trained on ImageNet, excluding the top layers\n",
        "    vgg = VGG19(weights='imagenet', include_top=False, input_shape=hr_shape)\n",
        "    vgg_layers = vgg.layers[:10]  # Use the first 10 layers\n",
        "\n",
        "    # Define the input tensor and a convolutional layer to convert the input to 3 channels\n",
        "    input_tensor = Input(shape=(144, 320, 1))\n",
        "    x = Conv2D(3, (3, 3), padding='same')(input_tensor)\n",
        "\n",
        "    # Pass the input through the VGG layers\n",
        "    out = x\n",
        "    for layer in vgg_layers[1:]:\n",
        "        out = layer(out)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=out, name='vgg')\n",
        "\n",
        "# Define a combined model for training the generator with the discriminator and VGG feature extractor\n",
        "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
        "    # Generate the high-resolution image from the low-resolution input\n",
        "    gen_img = gen_model(lr_ip)\n",
        "\n",
        "    # Extract features from the generated image using the VGG model\n",
        "    gen_features = vgg(gen_img)\n",
        "\n",
        "    # Make the discriminator untrainable in the combined model\n",
        "    disc_model.trainable = False\n",
        "\n",
        "    print(gen_img.shape)\n",
        "\n",
        "    # Get the validity score from the discriminator\n",
        "    validity = disc_model(gen_img)\n",
        "\n",
        "    return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Create the generator model with 16 residual blocks\n",
        "generator = create_gen(lr_ip, num_res_block=16)\n",
        "generator.summary()\n",
        "\n",
        "# Define the learning rate schedule for the generator using exponential decay\n",
        "gen_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.0001,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.1,\n",
        "    staircase=True\n",
        ")\n",
        "\n",
        "# Define the learning rate schedule for the discriminator using exponential decay\n",
        "disc_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.0004,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.1,\n",
        "    staircase=True\n",
        ")\n",
        "\n",
        "# Create and compile the discriminator model\n",
        "discriminator = create_disc(hr_ip)\n",
        "discriminator.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=disc_schedule),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "discriminator.summary()\n",
        "\n",
        "# Build the VGG model for feature extraction\n",
        "vgg = build_vgg((144, 240, 3))\n",
        "print(vgg.summary())\n",
        "vgg.trainable = False  # Make the VGG model untrainable\n",
        "\n",
        "# Create the combined GAN model\n",
        "gan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)\n",
        "gan_model.compile(\n",
        "    loss=['binary_crossentropy', 'mse'],\n",
        "    loss_weights=[1e-3, 1],\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=gen_schedule)\n",
        ")\n",
        "gan_model.summary()\n",
        "\n",
        "# Define the batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# Create lists to store training and validation batches\n",
        "train_lr_batches = []\n",
        "train_hr_batches = []\n",
        "val_lr_batches = []\n",
        "val_hr_batches = []\n",
        "\n",
        "# Create training and validation batches\n",
        "for it in range(int(hr_train.shape[0] / batch_size)):\n",
        "    start_idx = it * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    train_hr_batches.append(hr_train[start_idx:end_idx])\n",
        "    train_lr_batches.append(lr_train[start_idx:end_idx])\n",
        "    val_hr_batches.append(hr_val[start_idx:end_idx])\n",
        "    val_lr_batches.append(lr_val[start_idx:end_idx])\n"
      ],
      "metadata": {
        "id": "CC2Q083Dzuyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 600\n",
        "\n",
        "# Assuming these variables are initialized elsewhere in your code:\n",
        "# train_lr_batches, train_hr_batches, val_lr_batches, val_hr_batches\n",
        "# generator, discriminator, gan_model, vgg\n",
        "\n",
        "loss_d = []\n",
        "loss_g = []\n",
        "val_loss_g = []\n",
        "val_loss_d = []  # Combined validation loss for the discriminator\n",
        "\n",
        "for e in range(epochs):\n",
        "    fake_label = np.zeros((batch_size, 1))\n",
        "    real_label = np.ones((batch_size, 1))\n",
        "\n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "\n",
        "    # Training loop\n",
        "    for b in tqdm(range(len(train_hr_batches))):\n",
        "        lr_imgs = train_lr_batches[b]\n",
        "        hr_imgs = train_hr_batches[b]\n",
        "\n",
        "        fake_imgs = generator.predict_on_batch(lr_imgs)\n",
        "\n",
        "        discriminator.trainable = True\n",
        "        d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
        "        d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
        "\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real)\n",
        "\n",
        "        image_features = vgg.predict(hr_imgs)\n",
        "\n",
        "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n",
        "\n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_loss)\n",
        "\n",
        "    # Validation loop\n",
        "    val_g_losses = []\n",
        "    val_d_losses = []\n",
        "    for b in range(len(val_hr_batches)):\n",
        "        val_lr_imgs = val_lr_batches[b]\n",
        "        val_hr_imgs = val_hr_batches[b]\n",
        "\n",
        "        # Skip the batch if it's empty\n",
        "        if val_lr_imgs.size == 0 or val_hr_imgs.size == 0:\n",
        "            continue\n",
        "\n",
        "        val_fake_imgs = generator.predict_on_batch(val_lr_imgs)\n",
        "\n",
        "        # Adjust the label sizes to match the validation batch size\n",
        "        current_batch_size = val_lr_imgs.shape[0]\n",
        "        val_real_label = np.ones((current_batch_size, 1))\n",
        "        val_fake_label = np.zeros((current_batch_size, 1))\n",
        "\n",
        "        # Evaluate discriminator on real and fake images\n",
        "        val_d_loss_real = discriminator.evaluate(val_hr_imgs, val_real_label, verbose=0)\n",
        "        val_d_loss_fake = discriminator.evaluate(val_fake_imgs, val_fake_label, verbose=0)\n",
        "        val_d_loss = 0.5 * np.add(val_d_loss_real[0], val_d_loss_fake[0])  # Assuming 0th index is loss\n",
        "\n",
        "        val_image_features = vgg.predict(val_hr_imgs)\n",
        "        val_g_loss, _, _ = gan_model.evaluate([val_lr_imgs, val_hr_imgs], [val_real_label, val_image_features], verbose=0)\n",
        "\n",
        "        val_g_losses.append(val_g_loss)\n",
        "        val_d_losses.append(val_d_loss)\n",
        "\n",
        "    # Calculate average losses\n",
        "    avg_g_loss = np.mean(g_losses)\n",
        "    avg_d_loss = np.mean(d_losses)\n",
        "    avg_val_g_loss = np.mean(val_g_losses)\n",
        "    avg_val_d_loss = np.mean(val_d_losses)  # Combined average validation D loss\n",
        "\n",
        "    # Store the average losses\n",
        "    loss_g.append(avg_g_loss)\n",
        "    loss_d.append(avg_d_loss)\n",
        "    val_loss_g.append(avg_val_g_loss)\n",
        "    val_loss_d.append(avg_val_d_loss)  # Adjusted to combined validation D loss\n",
        "\n",
        "    print(f'Epoch: {e + 1}, Training G Loss: {avg_g_loss}, Training D Loss: {avg_d_loss}, Validation G Loss: {avg_val_g_loss}, Validation D Loss: {avg_val_d_loss}')\n",
        "\n",
        "    # Saving the generator model\n",
        "    if (e + 1) % 1 == 0:\n",
        "        generator.save(f'SRGAN_large_region_gen_e_{e + 1}.h5')"
      ],
      "metadata": {
        "id": "6NYir1aDz68d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4rLsS2trni8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot discriminator loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(epochs), loss_d, label='Training D Loss')\n",
        "plt.plot(range(epochs), val_loss_d, label='Validation D Loss')\n",
        "plt.title('Discriminator Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot generator loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(epochs), loss_g, label='Training G Loss')\n",
        "plt.plot(range(epochs), val_loss_g, label='Validation G Loss')\n",
        "plt.title('Generator Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "# Save the figure\n",
        "plt.savefig('SRGAN_4_times_large_region_loss_plot.png', bbox_inches='tight)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD-H4dPiOvLx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# SSIM (Structural Similarity Index) loss function\n",
        "def ssim_loss(gen_image, tar_image):\n",
        "    ssim_val = tf.image.ssim(\n",
        "        gen_image,\n",
        "        tar_image,\n",
        "        max_val=1,\n",
        "        filter_size=11,\n",
        "        filter_sigma=1.5,\n",
        "        k1=0.01,\n",
        "        k2=0.03,\n",
        "        # return_index_map=False  # Not needed as it defaults to False\n",
        "    )\n",
        "\n",
        "    return tf.reduce_mean(ssim_val)\n",
        "\n",
        "# PSNR (Peak Signal-to-Noise Ratio) loss function\n",
        "def psnr_loss(gen_image, tar_image):\n",
        "    psnr_val = tf.image.psnr(\n",
        "        gen_image,\n",
        "        tar_image,\n",
        "        max_val=1\n",
        "    )\n",
        "    return tf.reduce_mean(psnr_val)\n",
        "\n",
        "# MAE (Mean Absolute Error) loss function\n",
        "def mae_loss(gen_image, tar_image):\n",
        "    # Initialize an empty list to store losses\n",
        "    loss = []\n",
        "\n",
        "    # Compute MAE for each image in the batch\n",
        "    for i in range(len(gen_image[:,0,0,0])):\n",
        "        loss.append(np.mean(np.abs(gen_image[i,:,:,:] - tar_image[i,:,:,:])))\n",
        "\n",
        "    # Return the mean of all MAE losses\n",
        "    return np.array(loss).mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6wK66oVOvGD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "epochs = []\n",
        "ssim_ = []\n",
        "psnr_ = []\n",
        "mae_ = []\n",
        "\n",
        "# Evaluate on test dataset\n",
        "for i in range(600):\n",
        "    generator = load_model(f'SRGAN_large_region_gen_e_{i+1}.h5', compile=False)\n",
        "    gen_image = generator.predict(lr_test)\n",
        "\n",
        "    ssim_.append(ssim_loss(gen_image, hr_test))\n",
        "    psnr_.append(psnr_loss(gen_image, hr_test))\n",
        "    mae_.append(mae_loss(gen_image, hr_test))\n",
        "    epochs.append(i+1)\n",
        "\n",
        "# Create a DataFrame for test dataset evaluation\n",
        "test_loss_df = pd.DataFrame({\n",
        "    'Epochs': epochs,\n",
        "    'PSNR': np.array(psnr_),\n",
        "    'SSIM': np.array(ssim_),\n",
        "    'MAE': mae_\n",
        "})\n",
        "\n",
        "# Save test dataset evaluation to CSV\n",
        "test_loss_df.to_csv('SRGAN_4_times_test_loss_data.csv', index=False)\n",
        "\n",
        "# Initialize lists to store evaluation metrics for train dataset\n",
        "epochs = []\n",
        "ssim_ = []\n",
        "psnr_ = []\n",
        "mae_ = []\n",
        "\n",
        "# Evaluate on train dataset\n",
        "for i in range(600):\n",
        "    generator = load_model(f'SRGAN_large_region_gen_e_{i+1}.h5', compile=False)\n",
        "    gen_image = generator.predict(lr_train)\n",
        "\n",
        "    ssim_.append(ssim_loss(gen_image, hr_train))\n",
        "    psnr_.append(psnr_loss(gen_image, hr_train))\n",
        "    mae_.append(mae_loss(gen_image, hr_train))\n",
        "    epochs.append(i+1)\n",
        "\n",
        "# Create a DataFrame for train dataset evaluation\n",
        "train_loss_df = pd.DataFrame({\n",
        "    'Epochs': epochs,\n",
        "    'PSNR': np.array(psnr_),\n",
        "    'SSIM': np.array(ssim_),\n",
        "    'MAE': mae_\n",
        "})\n",
        "\n",
        "# Save train dataset evaluation to CSV\n",
        "train_loss_df.to_csv('SRGAN_4_times_train_loss_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ebl1EG8JayUK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from numpy.random import randint\n",
        "\n",
        "# Load the trained generator model\n",
        "generator = load_model('SRGAN_large_region_gen_e_600.h5', compile=False)\n",
        "\n",
        "# Select random samples from the training dataset\n",
        "[X1, X2] = [lr_train, hr_train]\n",
        "\n",
        "# Generate and display super-resolved images for 10 random samples\n",
        "for _ in range(10):\n",
        "    ix = randint(0, len(X1), 1)\n",
        "    src_image, tar_image = X1[ix], X2[ix]\n",
        "\n",
        "    # Generate super-resolved image\n",
        "    gen_image = generator.predict(src_image)\n",
        "\n",
        "    # Plot LR image, super-resolved image, and original HR image\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    plt.subplot(231)\n",
        "    plt.title('LR Image')\n",
        "    plt.imshow(src_image[0, :, :, 0], cmap='jet')  # Assuming single-channel input, adjust cmap if needed\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(232)\n",
        "    plt.title('Superresolved Image')\n",
        "    plt.imshow(gen_image[0, :, :, 0], cmap='jet')  # Assuming single-channel output, adjust cmap if needed\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(233)\n",
        "    plt.title('Original HR Image')\n",
        "    plt.imshow(tar_image[0, :, :, 0], cmap='jet')  # Assuming single-channel target, adjust cmap if needed\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1D10loVF5Gb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from numpy.random import randint\n",
        "\n",
        "# Load the trained generator model\n",
        "generator = load_model('SRGAN_large_region_gen_e_600.h5', compile=False)\n",
        "\n",
        "# Select random samples from the test dataset\n",
        "[X1, X2] = [lr_test, hr_test]\n",
        "\n",
        "# Generate and display super-resolved images for 10 random samples from the test dataset\n",
        "for _ in range(10):\n",
        "    ix = randint(0, len(X1), 1)\n",
        "    src_image, tar_image = X1[ix], X2[ix]\n",
        "\n",
        "    # Generate super-resolved image\n",
        "    gen_image = generator.predict(src_image)\n",
        "\n",
        "    # Plot LR image, super-resolved image, and original HR image\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    plt.subplot(231)\n",
        "    plt.title('LR Image')\n",
        "    plt.imshow(src_image[0, :, :, 0], cmap='jet')  # Assuming single-channel input, adjust cmap if needed\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(232)\n",
        "    plt.title('Superresolved Image')\n",
        "    plt.imshow(gen_image[0, :, :, 0], cmap='jet')  # Assuming single-channel output, adjust cmap if needed\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(233)\n",
        "    plt.title('Original HR Image')\n",
        "    plt.imshow(tar_image[0, :, :, 0], cmap='jet')  # Assuming single-channel target, adjust cmap if needed\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oB3uCtUvll0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUGofAGdvll0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaYZrdDsvll1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iC76WYjvll1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wyGE-RHvll1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06szG3d3vll1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxL3VA3vvll1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwPIghnUvll1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYrLTO4lvll1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}